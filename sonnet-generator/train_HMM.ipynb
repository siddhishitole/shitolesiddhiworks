{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import HMM\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "dictionary = set()\n",
    "with open('data/Syllable_dictionary.txt') as f:\n",
    "    for line in f:\n",
    "        word_list.append(line.split()[0])\n",
    "        dictionary.add(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    punctuation = [',','.',':','?',';','!',\"'\",'\"', '(', ')']\n",
    "    for i, word in enumerate(words):\n",
    "        word = word.lower()\n",
    "\n",
    "        while word not in dictionary:\n",
    "            \n",
    "            if word[-1] in punctuation:\n",
    "                word = word[:-1]\n",
    "\n",
    "            if word[0] in punctuation and word not in dictionary:\n",
    "                word = word[1:]\n",
    "\n",
    "        words[i] = word\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training sequences by grouping every quatrain and couplet together. The data is tokenized by words, which are uncapitalized and have punctuation that is not part of the word removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        start = 0\n",
    "        current = []\n",
    "        for i, line in enumerate(f):\n",
    "            words = line.split()\n",
    "            if len(words) < 1:\n",
    "                continue\n",
    "\n",
    "            if len(words) == 1:\n",
    "                start = i\n",
    "                continue\n",
    "\n",
    "            words = remove_punctuation(words)\n",
    "            current.extend(words) \n",
    "\n",
    "            if i == start + 4 or i == start + 8 or i == start + 12 or \\\n",
    "            i == start + 14:\n",
    "                data.append(current)\n",
    "                current = []\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign each word to a unique integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data_HMM(data):\n",
    "    encoding = {}\n",
    "    for i, word in enumerate(word_list):\n",
    "        encoding[word] = i\n",
    "    \n",
    "    encoded_data = []\n",
    "    for x in data:\n",
    "        encoded_x = []\n",
    "        for word in x:\n",
    "            encoded_x.append(encoding[word])\n",
    "        encoded_data.append(encoded_x)\n",
    "        \n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n"
     ]
    }
   ],
   "source": [
    "data = load_data('data/shakespeare.txt')\n",
    "data_HMM = encode_data_HMM(data)\n",
    "print(len(data_HMM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to train new HMM, otherwise load a pretrained HMM from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(HMM)\n",
    "# model = HMM.unsupervised_HMM(data_HMM, 6, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMM.load_from_file('models/HMM.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_emission(emission):\n",
    "    decoded = []\n",
    "    for word in emission:\n",
    "        decoded.append(word_list[word])\n",
    "    \n",
    "    return ' '.join(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission = decode_emission(model.generate_emission(20)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flown of he no brain constant mud assailed travail creature of now my hidden please when some believe the april\n"
     ]
    }
   ],
   "source": [
    "print(emission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "37_env",
   "language": "python",
   "name": "37_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
